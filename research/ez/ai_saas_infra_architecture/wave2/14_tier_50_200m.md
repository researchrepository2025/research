# Tier Analysis: AI SaaS Companies at $50-200M ARR

## Tier Context

**Revenue Range:** $50-200M ARR
**Company Profile:** Scale-up stage. Dedicated platform/SRE teams (5-15 infrastructure engineers). Multi-region requirements emerging. Compliance (SOC 2 Type II, ISO 27001, HIPAA/GDPR depending on vertical) becoming important. Series C/D funded or approaching profitability. Engineering orgs of 100-400 total engineers.

**Date Compiled:** 2026-02-12

---

## 1. Architecture Distribution Estimates

### 1a. Cloud-Native (Non-K8s Managed): 25-35%

**Classification:** Estimated

**Estimate: ~30% of AI SaaS companies at $50-200M ARR use cloud-native non-K8s managed services as their PRIMARY architecture.**

This category includes serverless (Lambda, Cloud Functions), PaaS (Heroku, Render), and managed containers without Kubernetes (ECS/Fargate, Cloud Run, Azure Container Apps).

**Evidence chain:**

1. Based on [01_cncf_survey.md, Data Point 31], which shows only 11% of CNCF respondents use serverless computing frameworks (2024), and [01_cncf_survey.md, Data Point 32], which shows serverless dropped from 22% (2022) to 13% (2023). However, the CNCF survey respondent base is biased toward Kubernetes practitioners, systematically under-counting serverless-primary organizations.

2. Based on [02_analyst_reports.md, Data Points 13-16], Datadog telemetry shows serverless container adoption is substantial: 68% of Google Cloud container organizations use serverless containers (Cloud Run), 65% of AWS customers use Lambda, and 56% of Azure customers use Azure App Service. These figures include organizations that use serverless alongside Kubernetes, not exclusively.

3. Based on [02_analyst_reports.md, Data Point 17], 66% of organizations using serverless functions also use container orchestration, confirming that hybrid (serverless + K8s) is common rather than pure serverless.

4. Based on [05_cloud_vendor_cases.md, Case Studies 10-12], AWS features ECS/Fargate case studies for SaaS companies including Autodesk, BILL (150K-200K requests/minute), and Smartsheet. Based on [05_cloud_vendor_cases.md, Case Study 18], Coca-Cola used Azure Container Apps for a 43-market AI campaign. These demonstrate that non-K8s managed services can handle substantial scale.

5. Based on [08_vc_startup_db.md], startup infrastructure guidance recommends avoiding Kubernetes at seed/Series A stages, with serverless and PaaS as default. Companies that started on serverless/ECS pre-$50M and have not yet migrated remain in this category.

**Reasoning for 25-35% range:**
- At $50-200M ARR, many companies originally built on serverless/ECS in earlier stages. Some have migrated to K8s (like Figma, per [04_tech_blogs.md]), but others remain on non-K8s platforms because the architecture works well for their workload profiles.
- The Datadog data showing 65-70% of cloud customers use serverless includes all company sizes, but the CNCF 11% figure is artificially depressed by survey selection bias.
- AI SaaS companies at this tier with primarily API-based products (wrapping foundation models) may not need Kubernetes complexity and can run effectively on ECS/Fargate or Cloud Run.
- The 25% floor reflects companies for whom serverless/managed containers genuinely serve their needs at scale. The 35% ceiling accounts for companies that have not yet found compelling reasons to migrate to K8s.

**Assumption A1:** Companies at $50-200M ARR had enough time and resources to migrate away from early-stage serverless if they wanted to. Those still on non-K8s are there by choice, not inertia.
**Assumption A2:** "Cloud-native non-K8s" includes companies using ECS/Fargate as primary compute alongside serverless functions, which is a meaningful production architecture at this scale (BILL case study demonstrates this).

---

### 1b. Managed Kubernetes (EKS/AKS/GKE): 55-65%

**Classification:** Inferred

**Estimate: ~60% of AI SaaS companies at $50-200M ARR use managed Kubernetes as their PRIMARY architecture.**

**Evidence chain:**

1. Based on [02_analyst_reports.md, Data Point 1], Dynatrace reports 73% of cloud Kubernetes clusters run on managed distributions (EKS/AKS/GKE). Based on [01_cncf_survey.md, Data Point 37], managed Kubernetes services host 61% of all production clusters. These figures apply to general enterprise, not AI SaaS specifically.

2. Based on [06_stackshare_github.md], the Jeevi Academy source reports two out of every three Kubernetes clusters (67%) are now cloud-hosted, up from 45% in 2022, indicating strong shift toward managed services.

3. Based on [04_tech_blogs.md], engineering blog disclosures from companies in or near this tier show strong managed K8s adoption:
   - Figma migrated FROM ECS TO EKS [04_tech_blogs.md, Figma migration case study]
   - Grammarly migrated FROM EC2 TO EKS [04_tech_blogs.md, Grammarly case study]
   - Cohere runs on Oracle Kubernetes Engine (OKE) [04_tech_blogs.md, Cohere case study]
   - Notion uses EKS for data infrastructure [04_tech_blogs.md, Notion case study]
   - Jasper AI runs Kubernetes with developer tooling abstraction [04_tech_blogs.md, Jasper case study]

4. Based on [05_cloud_vendor_cases.md], vendor case studies show managed K8s for AI SaaS: Flawless (EKS Hybrid Nodes for AI rendering), Liquid Analytics (EKS with 1,000 pods in 1.2 seconds), Instabase (EKS for GenAI document processing), Sonantic (EKS with GPU for AI voice synthesis), Picterra (GKE for geospatial AI), Stacks (GKE Autopilot for accounting AI).

5. Based on [03_job_postings.md, Data Point 4], 73% of cloud Kubernetes clusters are on managed distributions. Based on [03_job_postings.md, Data Point 7], 91% of Kubernetes users are at organizations exceeding 1,000 employees. Companies at $50-200M ARR typically have 100-400+ employees; those at the upper end (closer to 1,000) strongly correlate with K8s adoption.

6. Based on [07_sec_earnings.md], CNCF Voice of Kubernetes Experts Report 2024 shows 54% of enterprises build AI/ML workloads on Kubernetes, and more than two-thirds say Kubernetes infrastructure is "key" to taking full advantage of AI.

**Reasoning for 55-65% range:**
- The $50-200M tier has the engineering capacity (dedicated platform/SRE teams of 5-15 people) to operate managed Kubernetes effectively.
- Migration patterns in [04_tech_blogs.md] are uniformly TOWARD managed K8s (Figma: ECS to EKS, Grammarly: EC2 to EKS), with zero disclosed migrations away from K8s.
- At this scale, companies need multi-region deployment, advanced autoscaling (GPU workloads), and ecosystem tooling (Helm, Argo CD, Karpenter) that managed K8s provides.
- The 55% floor accounts for companies that remain on serverless/ECS or have gone to self-managed K8s. The 65% ceiling reflects that managed K8s is the dominant but not universal choice.
- AI-specific workloads (model serving, inference, batch training) strongly favor Kubernetes due to GPU scheduling, custom resource definitions, and the CNCF AI conformance ecosystem.

**Assumption A3:** Companies at $50-200M ARR that use Kubernetes predominantly use managed services (EKS/AKS/GKE) rather than self-managed, because the operational overhead of managing control planes is not justified when managed alternatives exist at this tier.
**Assumption A4:** The engineering blog and case study evidence, while subject to publication bias, directionally represents the real architecture preference at this tier because companies of this size actively choose their infrastructure (not defaulting by inertia).

---

### 1c. Open/Self-Managed Kubernetes: 8-15%

**Classification:** Estimated

**Estimate: ~10% of AI SaaS companies at $50-200M ARR use self-managed Kubernetes (without managed control plane) as their PRIMARY architecture.**

**Evidence chain:**

1. Based on [02_analyst_reports.md, Data Point 1], 27% of cloud Kubernetes clusters are self-managed (Dynatrace 2023). Based on [02_analyst_reports.md, Data Point 2], across all environments (including on-prem), 37% of Kubernetes deployments are self-managed (Tigera 2025 compilation).

2. Based on [01_cncf_survey.md, Data Point 20], the 2024 CNCF survey shows deployments "skewing heavily toward self-managed instances" in both on-prem and public cloud environments. However, 46% use managed public cloud, and the overlap between managed and self-managed is substantial (organizations using both).

3. Based on [04_tech_blogs.md], self-managed K8s appears primarily at companies above this tier:
   - OpenAI runs self-managed K8s at 7,500 nodes on Azure (but OpenAI is well above $200M ARR)
   - Salesforce deploys K8s on bare metal (enterprise-scale, well above this tier)
   - Databricks runs a hybrid of managed and self-managed across thousands of clusters (above this tier)
   - HubSpot has a long history with self-managed K8s (in the tier or slightly above)

4. Based on [06_stackshare_github.md], the shift from 45% cloud-hosted K8s in 2022 to 67% in 2025 means the self-managed share is declining over time. For SaaS companies (cloud-native by default), the self-managed fraction is likely even lower than the 33% overall figure because SaaS companies have less on-prem infrastructure than mixed enterprises.

**Reasoning for 8-15% range:**
- Self-managed K8s at $50-200M requires 3-5 dedicated K8s infrastructure engineers just for control plane management, etcd operations, upgrades, and security patching. This is feasible but expensive at this tier.
- Companies in this tier choosing self-managed K8s typically have: (a) specific compliance/isolation requirements, (b) extreme customization needs for GPU scheduling, (c) historical investment they haven't yet migrated, or (d) multi-cloud portability requirements that managed services don't satisfy.
- The 8% floor reflects the small subset with genuine technical requirements for self-managed. The 15% ceiling accounts for companies that adopted self-managed K8s earlier and haven't migrated to managed services yet.
- Based on [08_vc_startup_db.md], CoreWeave provides "Kubernetes native cloud built for large, GPU-accelerated workloads," suggesting some AI companies use specialized K8s clouds that are technically managed but operate differently from hyperscaler managed K8s. These are counted as managed K8s in this analysis.

**Assumption A5:** "Self-managed Kubernetes" at this tier means the company operates its own K8s control plane on cloud VMs or bare metal. Companies using CoreWeave, Civo, or similar K8s-native clouds are classified as managed K8s.
**Assumption A6:** The declining trend in self-managed K8s (from 55% in 2022 to 33% in 2025 per [06_stackshare_github.md]) applies more strongly to SaaS companies than to enterprises with on-prem legacy.

---

### 1d. Architecture Overlap (Multiple Architectures): 40-55%

**Classification:** Estimated

**Estimate: ~45% of AI SaaS companies at $50-200M ARR use MULTIPLE architecture categories simultaneously.**

**Evidence chain:**

1. Based on [02_analyst_reports.md, Data Point 17], 66% of organizations using serverless functions also use container orchestration. This directly demonstrates that hybrid architectures (serverless + K8s) are common.

2. Based on [01_cncf_survey.md, Data Point 9], 56% of organizations use multi-cloud solutions, and the average organization uses 2.8 unique cloud service providers. Multi-cloud often implies multiple architecture patterns.

3. Based on [02_analyst_reports.md, Data Points 28-29], Flexera reports 70% embrace hybrid cloud strategies and organizations use an average of 2.4 public cloud providers.

4. Based on [04_tech_blogs.md], Databricks explicitly operates a hybrid of managed and self-managed K8s across EKS, AKS, and GKE. Anthropic uses multi-cloud K8s (GKE + AWS + Azure). These demonstrate that even K8s-primary companies use multiple architectures.

5. Based on [05_cloud_vendor_cases.md], companies like Liquid Analytics use EKS alongside Amazon Bedrock (managed AI platform), showing K8s + managed AI services co-existing.

**Reasoning:**
- At $50-200M, AI SaaS companies typically have: (a) a primary compute platform (usually managed K8s or ECS/Fargate), (b) serverless functions for event-driven workloads (webhooks, async processing), (c) managed AI platform services (SageMaker, Vertex AI, Bedrock) for some inference, and (d) possibly specialized GPU infrastructure (CoreWeave, dedicated instances).
- The "primary architecture" percentages in sections 1a-1c sum to more than 100% because categories are non-exclusive.
- 40% floor assumes some companies maintain disciplined single-architecture stacks. 55% ceiling accounts for the natural tendency to adopt best-fit services across providers and models.

**Assumption A7:** "Multiple architectures" means the company runs meaningful production workloads (not just dev/test) on more than one architecture category.

---

## 2. Typical Architecture Patterns

### 2a. Most Common Starting Architecture (Pre-$50M)

**Classification:** Inferred

Based on [08_vc_startup_db.md], startup infrastructure guides recommend:
- **Seed stage:** PaaS (Heroku, Vercel, Firebase) or serverless (Lambda) to minimize infrastructure overhead
- **Series A:** Structured environments with IaC, moving toward ECS/Fargate or managed containers
- **Series B:** Introduction of Kubernetes if workload complexity demands it

Based on [08_vc_startup_db.md], 66% of YC Winter 2024 startups integrate AI, and 58% accept Azure credits, suggesting early-stage AI companies start on cloud-native managed services rather than self-managed infrastructure.

**Most common entry architecture for companies reaching $50M ARR:** ECS/Fargate or early-stage EKS, having graduated from PaaS/serverless in the $5-20M range. Some arrive at $50M already on managed K8s; others are still on ECS/Fargate and evaluating migration.

---

### 2b. Migration Patterns at This Tier

**Classification:** Inferred

Based on [04_tech_blogs.md], documented migrations in 2024-2025 are uniformly toward Kubernetes:
- **Figma:** ECS to EKS in <12 months. Reasons: cost savings, developer experience, CNCF ecosystem access (StatefulSets, Helm, Temporal). [04_tech_blogs.md, Figma migration]
- **Grammarly:** EC2 to EKS for ML infrastructure. Reasons: decouple storage from compute, dynamic resource allocation, reduced setup time. [04_tech_blogs.md, Grammarly migration]
- **Salesforce Data Cloud:** EC2 to Kubernetes in 6 months. [04_tech_blogs.md, Salesforce]

Based on [04_tech_blogs.md], no engineering blog disclosures found of companies migrating AWAY from Kubernetes to serverless or other architectures.

**Typical migration pattern at $50-200M:**
1. Company hits scaling/tooling limitations on ECS/Fargate or serverless
2. Platform team evaluates managed K8s (EKS/GKE/AKS based on existing cloud provider)
3. Migration takes 6-12 months with incremental cutover
4. Post-migration: K8s becomes primary, but serverless retained for specific workloads (event-driven, edge)

**Assumption A8:** Publication bias in engineering blogs means failed K8s migrations or K8s-to-serverless migrations are under-reported. However, the consistent direction of disclosed migrations (toward K8s) is a meaningful signal.

---

## 3. Engineering Team Size and Capability

### 3a. Typical Infrastructure Team at $50-200M ARR

**Classification:** Estimated

Based on [08_vc_startup_db.md], platform engineering adoption has reached 55% of global organizations, with 65% of enterprises having built or adopted an Internal Developer Platform. Based on [03_job_postings.md, Data Point 8], Platform Engineer roles represent 8-11% of infrastructure job postings and are growing at 32% YoY.

**Estimated team composition:**
- **Total engineering org:** 100-400 engineers (based on typical SaaS ratios of 1 engineer per $500K-$2M ARR)
- **Platform/Infrastructure team:** 5-15 engineers (5-8% of total engineering)
  - 2-4 Platform Engineers (K8s platform, IDP)
  - 1-3 SRE/Reliability Engineers
  - 1-2 Security/DevSecOps Engineers
  - 1-2 Data Infrastructure Engineers
  - 0-2 MLOps/AI Infrastructure Engineers

Based on [03_job_postings.md, Data Point 20], 60% of DevOps positions require senior-level experience, and K8s-specific roles command $158K-$167K average salary. Platform Engineers earn 20% more than general DevOps ($170K vs $142K). This salary premium indicates talent scarcity.

### 3b. Can This Tier Run Self-Managed K8s?

**Classification:** Inferred

**Yes, but with significant trade-offs.**

Based on [03_job_postings.md, Data Point 16], K8s-specific roles average $158K-$167K globally and $170K+ in North America. A self-managed K8s team of 3-5 engineers focused on control plane operations would cost $500K-$850K annually in salary alone before benefits, tooling, and infrastructure costs.

Based on [04_tech_blogs.md, HubSpot case study], HubSpot scaled 400 MySQL databases on self-managed K8s with an infrastructure team of 3-5 people. This demonstrates feasibility at scale but also shows the required concentration of expertise.

**Assessment:** Companies at $50-200M CAN run self-managed K8s but MOST SHOULD NOT because:
1. The 3-5 senior K8s engineers required represent 20-50% of the entire platform team
2. Based on [02_analyst_reports.md, Data Point 1], managed K8s handles 73% of cloud clusters, indicating the market has voted for managed services at comparable scale
3. The opportunity cost of dedicating senior engineers to control plane management rather than product differentiation is high at this revenue tier
4. Based on [08_vc_startup_db.md], CAST AI customers save 50-60% on K8s costs through optimization, suggesting the economic case for self-managed (cost savings) can be partially captured through managed K8s optimization tools

**Exception cases where self-managed K8s is justified at this tier:**
- Extreme GPU scheduling customization (custom schedulers for multi-tenant GPU sharing)
- Regulatory requirements mandating control plane isolation
- Multi-cloud portability requirements not met by managed K8s
- Companies with existing deep K8s expertise from founding team

---

## 4. Infrastructure Spend as Percentage of Revenue

### 4a. Total Infrastructure Cost

**Classification:** Inferred

**Estimate: 20-40% of revenue for AI SaaS at $50-200M ARR (infrastructure COGS), with a median around 30%.**

**Evidence chain:**

1. Based on [07_sec_earnings.md], AI SaaS companies see 40-50% of revenue consumed by COGS (model hosting, inference compute, data costs), compared to 15-30% for traditional SaaS. However, this 40-50% figure includes personnel in COGS, not just infrastructure.

2. Based on [08_vc_startup_db.md], traditional SaaS infrastructure costs are 5-15% of revenue (SaaStr benchmark: 5% for compute-lite, 8-10% average). AI startups start at 50-80% of revenue for compute costs at early stages, declining toward 24-40% at scale.

3. Based on [07_sec_earnings.md], AI SaaS gross margins target 50-65%, meaning COGS is 35-50%. Infrastructure (cloud compute, GPUs, storage) represents the largest component of COGS for AI SaaS, typically 60-80% of total COGS.

4. Based on [08_vc_startup_db.md], Bessemer Venture Partners found fast-scaling AI SaaS startups had ~25% gross margin in early stages, while steadier-growth AI companies managed ~60%. At $50-200M, companies should be approaching the 55-65% gross margin range if executing well.

5. Based on [07_sec_earnings.md], Datadog reports GPU instance spending grew from 10% to 14% of EC2 compute costs, and 83% of container costs were associated with idle resources. This suggests significant optimization headroom.

**Reasoning for 20-40% range:**
- At $50-200M ARR, companies have negotiated reserved instance/savings plan pricing (based on [07_sec_earnings.md], 59% of organizations use Savings Plans)
- Companies at this tier have dedicated FinOps or cost optimization efforts
- The 20% floor applies to companies whose AI workloads are lighter (API wrappers, lighter inference). The 40% ceiling applies to companies with heavy model hosting, training, and GPU-intensive inference
- The declining trajectory from early-stage (50-80%) to this tier (20-40%) reflects economies of scale and optimization maturity

**Assumption A9:** "Infrastructure spend" includes cloud compute, storage, networking, GPU instances, managed services, and third-party AI API costs (OpenAI/Anthropic API fees), but excludes infrastructure team salaries.
**Assumption A10:** Companies at $50-200M have had sufficient time and incentive to optimize infrastructure costs from early-stage levels.

---

### 4b. Infrastructure Cost by Architecture

**Classification:** Estimated

| Architecture | Est. Infra Cost as % of Revenue | Basis |
|---|---|---|
| Cloud-native non-K8s | 15-25% | Lower operational overhead, pay-per-use pricing, but limited optimization control. Based on [02_analyst_reports.md, Data Point 40], resource over-provisioning exists across all platforms. |
| Managed Kubernetes | 20-35% | Higher operational overhead but better optimization control (HPA, Karpenter, spot instances). Based on [05_cloud_vendor_cases.md, Case Study 2], Liquid Analytics achieved 63% savings on compute and 90% reduced CPU waste on EKS. |
| Self-managed Kubernetes | 18-30% | Lower compute costs (no managed K8s premium) but higher personnel costs. Net effect depends on scale. Justified only when team can capture the control plane savings. |

**Critical caveat:** These ranges overlap significantly. The architecture choice alone does not determine cost; workload characteristics (GPU-intensity, inference volume, data processing) are the dominant cost drivers.

---

## 5. Decision Drivers for Architecture Choice

### 5a. Primary Decision Drivers at $50-200M ARR

**Classification:** Inferred

Based on synthesis across all Wave 1 files, ranked by influence at this tier:

**1. Ecosystem and Tooling (HIGHEST INFLUENCE)**

Based on [04_tech_blogs.md, Figma migration], Figma migrated specifically to "take advantage of the large ecosystem supported by the CNCF" including StatefulSets, Helm charts, and OSS software like Temporal. At $50-200M, access to the CNCF ecosystem (200+ graduated/incubating projects) is a strong pull toward managed K8s.

Based on [06_stackshare_github.md], GitOps adoption has reached 77% of organizations. Based on [01_cncf_survey.md, Data Point 30], 58% of cloud-native innovators use GitOps extensively. The GitOps ecosystem (ArgoCD, Flux) is Kubernetes-native, creating gravitational pull toward K8s.

**2. Scalability and Multi-Region Requirements**

At $50-200M, companies are deploying across multiple regions for latency, compliance, and reliability. Based on [04_tech_blogs.md, Elastic case study], Elastic deployed across 4 AWS regions, 3 GCP regions, and 1 Azure region using K8s with Crossplane. Based on [05_cloud_vendor_cases.md, AKS fleet case study], AKS demonstrated 80 clusters across 6 geographic regions with 70,000 nodes.

Managed K8s provides the most portable multi-region deployment model. ECS/Fargate is AWS-only; Cloud Run is GCP-only.

**3. GPU and AI Workload Requirements**

Based on [01_cncf_survey.md, Data Point 21], 66% of organizations hosting generative AI models use Kubernetes for inference workloads. Based on [04_tech_blogs.md, CNCF AI Conformance], CNCF launched Certified Kubernetes AI Conformance to standardize GPU management, networking, and gang scheduling on K8s.

AI SaaS companies at this tier increasingly need GPU scheduling, and K8s has the most mature GPU scheduling ecosystem (NVIDIA GPU Operator, Volcano, Kueue).

**However:** Based on [06_stackshare_github.md, serverless platform comparison], Google Cloud Run and Azure Container Instances support GPU workloads while AWS Fargate does not. This limits non-K8s options for GPU workloads on AWS.

**4. Cost Optimization**

Based on [08_vc_startup_db.md], AI infrastructure costs run 24-50% of revenue. Cost optimization is existential at this tier. Based on [05_cloud_vendor_cases.md, Case Study 2], Liquid Analytics achieved 63% savings on compute using EKS with Karpenter and Spot Instances. Based on [04_tech_blogs.md, Figma], Figma cited cost savings as a primary migration driver.

K8s enables fine-grained resource optimization (right-sizing, bin-packing, spot/preemptible instances via Karpenter). Serverless provides automatic scaling but limits optimization control.

**5. Compliance and Security**

Based on [01_cncf_survey.md, Data Point 13], 40% cite security as the leading container challenge. Based on [06_stackshare_github.md], 87% of container images have high-risk vulnerabilities (Sysdig 2023). At $50-200M, companies face SOC 2, ISO 27001, and sometimes HIPAA/FedRAMP requirements.

Both managed K8s and serverless can meet compliance requirements, but K8s provides more granular network policy, pod security, and audit logging control. Based on [05_cloud_vendor_cases.md, Case Study 4], Sonantic achieved 100% compliance in AWS Security Hub on EKS.

**6. Developer Experience and Hiring**

Based on [03_job_postings.md, Data Point 2], Kubernetes appears in 28% of DevOps job postings and Docker in 42-60%. Based on [03_job_postings.md, Data Point 16], K8s roles command a 17% salary premium ($167K vs $142K). K8s expertise is scarce and expensive.

For serverless/ECS, the talent pool is broader (any developer can deploy to Lambda/Fargate). For K8s, dedicated platform engineers are needed. At $50-200M, companies can afford this team but must compete for talent.

Based on [04_tech_blogs.md, Jasper AI], Jasper built JasperCLI to abstract K8s complexity from developers, and Based on [08_vc_startup_db.md], 65% of enterprises have built or adopted Internal Developer Platforms. This suggests the trend is: adopt K8s, then build abstraction layers to shield developers from complexity.

### 5b. Decision Matrix Summary

| Factor | Favors Cloud-Native Non-K8s | Favors Managed K8s | Favors Self-Managed K8s |
|---|---|---|---|
| Team size < 5 infra engineers | Strong | Neutral | Against |
| GPU-intensive workloads | Weak (limited GPU support) | Strong | Strong |
| Multi-cloud requirement | Against (vendor-locked) | Strong | Very Strong |
| Compliance rigor | Moderate | Strong | Very Strong |
| Rapid iteration speed | Strong | Moderate | Weak |
| Cost optimization control | Weak | Strong | Very Strong |
| Ecosystem/tooling access | Limited | Very Strong | Very Strong |
| Hiring difficulty | Low | Moderate | High |

---

## 6. Assumptions Register

| ID | Assumption | Impact if Wrong | Mitigation |
|---|---|---|---|
| A1 | Companies at $50-200M on non-K8s are there by choice, not inertia | Would overstate non-K8s as deliberate architecture; actual % choosing non-K8s could be lower | Cross-reference with migration intent data if available |
| A2 | ECS/Fargate counts as meaningful production architecture at this scale | If ECS at this tier is always transitional, cloud-native non-K8s % should be lower | BILL case study validates ECS at 150-200K req/min |
| A3 | K8s users at this tier predominantly use managed services | If significant self-managed, managed K8s % too high and self-managed too low | Dynatrace 73% managed figure supports this for cloud |
| A4 | Blog/case study evidence is directionally representative | Publication bias could miss silent majority on different architectures | Triangulated with survey data, job postings, vendor cases |
| A5 | Specialized K8s clouds (CoreWeave, Civo) classified as managed K8s | If these are fundamentally different, category boundaries are wrong | Minimal impact; small share of total |
| A6 | Declining self-managed trend applies more strongly to SaaS than enterprise | If SaaS companies self-manage at enterprise rates, self-managed % too low | SaaS cloud-native DNA makes this assumption reasonable |
| A7 | "Multiple architectures" means meaningful production workloads on 2+ categories | If counting dev/test, overlap % would be much higher | Focus on primary production compute |
| A8 | Failed K8s migrations and K8s-to-serverless moves are under-reported | If common, migration pattern analysis is biased toward K8s | No mitigation possible with public data |
| A9 | Infrastructure spend excludes personnel, includes third-party AI API costs | If personnel included, cost ranges would be 5-15% higher | Explicitly stated in analysis |
| A10 | Companies at $50-200M have optimized from early-stage cost levels | If optimization is immature, actual costs could be higher than estimated | FinOps maturity varies; range accounts for this |

---

## 7. Evidence Gaps

### Critical Gaps (Would Materially Change Conclusions)

1. **No direct survey of AI SaaS companies by ARR tier.** All architecture distribution estimates are inferred from general enterprise data, case studies, and proxy signals. Based on [01_cncf_survey.md, Limitations], CNCF surveys do not segment by "AI SaaS companies," revenue tier, or SaaS vs non-SaaS. Based on [02_analyst_reports.md, Limitations], no analyst report provides a direct breakdown for "AI SaaS companies" specifically.

2. **No data on companies that tried and abandoned Kubernetes.** Based on [04_tech_blogs.md, Limitations], no engineering blog disclosed a failed K8s migration or decision to revert to serverless. This creates survivorship bias that may overstate K8s success rates.

3. **No infrastructure cost data segmented by ARR tier.** Based on [07_sec_earnings.md, Limitations], SEC data represents exclusively large-cap public companies ($200M+ ARR). Based on [08_vc_startup_db.md], cost benchmarks exist for "early stage" and "at scale" but not specifically $50-200M.

### Significant Gaps (Would Refine Estimates)

4. **No team size data by ARR tier.** Estimated infrastructure team sizes (5-15 engineers) are based on general SaaS ratios, not AI SaaS-specific data.

5. **No K8s vs serverless job posting ratio for AI companies.** Based on [03_job_postings.md, Limitation 1], no dataset provides head-to-head comparison of K8s vs serverless job postings. Based on [03_job_postings.md, Limitation 3], no dataset segments by company type (AI SaaS vs general tech).

6. **No data on when companies migrate from serverless to K8s.** Based on [08_vc_startup_db.md, Limitations], "When do companies typically move from serverless to K8s?" has no empirical answer.

7. **No self-managed K8s data for companies under 500 employees.** Based on [01_cncf_survey.md, Data Point 27], CNCF company size data stops at 500-1,000 employees (9% of K8s users); companies below 500 employees are not measured.

### Minor Gaps

8. **Limited geographic data.** Based on [03_job_postings.md, Limitation 7], 66-70% of K8s job data is North America. EU/APAC AI SaaS companies may have different architecture preferences driven by data sovereignty.

9. **No EKS vs AKS vs GKE breakdown for AI SaaS.** Based on [06_stackshare_github.md], GKE has 32% adoption, AKS 28%, but these figures are not segmented for AI SaaS or by company size within this tier.

10. **No data on operational complexity by architecture.** Based on [04_tech_blogs.md, Limitations], no disclosure of team sizes required to operate K8s infrastructure, incident rates, or reliability metrics by architecture type.

---

## 8. Confidence Assessment

### Overall Confidence: 5/10

| Sub-Area | Confidence | Classification | Reasoning |
|---|---|---|---|
| Managed K8s is most common at this tier | 7/10 | Inferred | Converging evidence from CNCF surveys, Dynatrace data, engineering blogs, vendor cases, job postings. Multiple independent sources point same direction. |
| Cloud-native non-K8s at 25-35% | 4/10 | Estimated | Serverless data is conflicting (11% CNCF vs 65-70% Datadog). No direct measurement for AI SaaS. ECS/Fargate adoption not independently measured. |
| Self-managed K8s at 8-15% | 4/10 | Estimated | General decline trend is clear, but SaaS-specific data absent. No visibility into companies <500 employees. |
| Multi-architecture at 40-55% | 5/10 | Estimated | Datadog's 66% serverless+orchestration overlap supports hybrid patterns. But "meaningful production workload" threshold is judgment-based. |
| Infrastructure spend 20-40% of revenue | 6/10 | Inferred | Multiple sources converge on AI SaaS having 2-4x higher infra costs than traditional SaaS. Range is wide due to workload variation. |
| Migration patterns toward K8s | 7/10 | Inferred | All disclosed migrations are toward K8s. Strong signal despite publication bias. |
| Team can run self-managed K8s | 8/10 | Direct | Directly supported by team size estimates and HubSpot case study showing 3-5 person team managing K8s at scale. |

### Why 5/10 Overall

**Score Drivers (+):**
- Multiple independent data sources (8 Wave 1 files) converge on K8s dominance
- Engineering blog evidence is specific, named, and verifiable
- Financial data (costs, margins) is well-documented from SEC filings and VC analyses
- Migration direction evidence is consistent and strong

**Score Reducers (-):**
- ZERO direct data for "AI SaaS companies at $50-200M ARR" -- every estimate requires inference
- Architecture distribution percentages are constructed from general enterprise data applied to a specific segment
- Publication bias in engineering blogs and vendor case studies systematically over-represents K8s
- Serverless adoption data is internally contradictory (11% CNCF vs 65-70% per cloud provider)
- Self-managed K8s data has a blind spot for companies under 500 employees
- No failure data: companies that chose wrong architecture and failed are invisible

---

## Sources

All data points cite specific Wave 1 files using the format [filename, Data Point N]. Primary sources referenced:

- [01_cncf_survey.md] - CNCF Annual Surveys 2021-2024 (n=750-3,800)
- [02_analyst_reports.md] - Analyst reports from Dynatrace, Datadog, Gartner, Flexera, HashiCorp
- [03_job_postings.md] - Job posting analysis from kube.careers, devopscube.com, Stack Overflow (n=4,850-110,000)
- [04_tech_blogs.md] - Engineering blogs from 15+ companies (OpenAI, Databricks, Figma, Grammarly, Anthropic, Cohere, HubSpot, Snowflake, Notion, Salesforce, Elastic, Jasper, Hugging Face)
- [05_cloud_vendor_cases.md] - 25+ vendor case studies from AWS, Azure, GCP
- [06_stackshare_github.md] - StackShare profiles, Datadog/Sysdig reports, CNCF/Red Hat surveys
- [07_sec_earnings.md] - SEC 10-K filings, earnings calls (Snowflake, Palantir, Salesforce, ServiceNow, Zoom, Atlassian, Elastic)
- [08_vc_startup_db.md] - VC reports from CB Insights, Bessemer, Battery, Menlo, Sequoia; startup databases

---

**Document Version:** 1.0
**Compiled By:** Analysis Agent (Wave 2)
**Methodology:** Cross-source triangulation of 8 Wave 1 fact-gathering files, applied to $50-200M ARR AI SaaS segment through inference chain analysis
**Known Limitation:** No primary data source directly segments "AI SaaS companies at $50-200M ARR" -- all estimates require inference from adjacent data
